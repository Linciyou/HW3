Metadata-Version: 2.4
Name: spam-analytics
Version: 0.1.0
Summary: Spam email analytics toolkit with preprocessing, modeling, and visualization utilities.
Author: HW3 Team
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Requires-Dist: pandas>=2.1
Requires-Dist: numpy>=1.25
Requires-Dist: scikit-learn>=1.3
Requires-Dist: matplotlib>=3.7
Requires-Dist: seaborn>=0.13
Requires-Dist: plotly>=5.18
Requires-Dist: typer>=0.12
Requires-Dist: rich>=13.7
Requires-Dist: streamlit>=1.31
Requires-Dist: joblib>=1.3
Requires-Dist: pyyaml>=6.0
Requires-Dist: nltk>=3.8
Provides-Extra: dev
Requires-Dist: pytest>=7.4; extra == "dev"
Requires-Dist: black>=23.9; extra == "dev"
Requires-Dist: isort>=5.12; extra == "dev"

# Spam Analytics Toolkit

Spam Analytics extends the classic SMS Spam dataset with a modernized preprocessing and visualization workflow. The toolkit offers:
- Reusable preprocessing utilities with rich step-by-step outputs.
- A scikit-learn training pipeline that produces evaluation metrics and artifacts.
- Command line tooling powered by Typer for quick experimentation.
- A Streamlit dashboard that surfaces dataset insights, preprocessing transformations, and model performance.

## Quick Start

```bash
python -m venv .venv
.venv\Scripts\activate
pip install --upgrade pip
pip install -e .
```

All commands assume you are in the project root (`HW3/`).
If you want preprocessing snapshots in Parquet format install an additional dependency:

```bash
pip install pyarrow
```

## Command Line Interface

`spam-analytics` exposes several sub-commands:

| Command | Description |
| --- | --- |
| `spam-analytics data summary` | Display dataset size, class distribution, and preview rows. |
| `spam-analytics data preprocess --limit 5` | Run the preprocessing pipeline and print intermediate columns. |
| `spam-analytics model train` | Train the classifier, log metrics, and persist artifacts to `artifacts/`. |
| `spam-analytics model evaluate` | Evaluate the latest trained model and refresh the reports in `reports/metrics.json`. |
| `spam-analytics visualize report` | Generate static figures (label balance, message length, most informative tokens). |

Run `spam-analytics --help` or append `--help` to any sub-command for details.

## Streamlit Dashboard

Launch the interactive dashboard:

```bash
streamlit run streamlit_app.py
```

The app provides dataset summaries, preprocessing step previews, performance charts, and an interactive text inference widget.

## Project Layout

```
.
├── artifacts/           # Serialized models, vectorizers, and configuration snapshots
├── dataset.csv          # SMS Spam dataset (input data)
├── pyproject.toml       # Build configuration and dependencies
├── reports/             # Generated metrics, figures, and exploratory summaries
├── src/
│   └── spam_analytics/
│       ├── cli.py               # Typer entry-point
│       ├── config.py            # Centralized configuration helpers
│       ├── data.py              # Dataset access utilities
│       ├── preprocessing.py     # Text cleaning and feature engineering primitives
│       ├── modeling.py          # sklearn pipeline assembly and persistence
│       ├── evaluation.py        # Metric computation and report writing
│       └── visualization.py     # Chart generation helpers
├── streamlit_app.py     # Streamlit dashboard
└── openspec.yaml        # High-level scenario specification
```

## Openspec Overview

`openspec.yaml` documents the primary workflows, inputs, and outputs for reproducibility, and can be used as a contract for future automation or documentation tooling.

## Development Notes

- All generated artifacts (models, metrics, figures) are stored under `artifacts/` and `reports/` by default.
- The preprocessing cache tries to save in Parquet; without `pyarrow` it gracefully falls back to CSV.
- The CLI emits rich logs that help inspect each processing step. Redirect output to a file for audit trails.
- Extend `visualization.py` with additional charting routines (confusion matrices, time series, top n-grams) as needed.

## Testing

Lightweight tests can be added under `tests/` (not included by default). To run them after adding:

```bash
pytest
```
